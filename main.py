import cv2 as cv
import numpy as np
from ultralytics import YOLO

# === ì‚¬ìš©ì ì„¤ì • ===
video_path = r"C:\Users\USER\Downloads\3team3-best\sample2.mp4"  # ì˜ìƒ ê²½ë¡œ
model_path = r"C:\Users\USER\Downloads\3team3-best\best.pt"      # YOLO ëª¨ë¸ ê²½ë¡œ

# === Kalman Filter (ì°¨ì„  ì¤‘ì‹¬ xì¢Œí‘œ ì˜ˆì¸¡ìš©) ===
lane_kalman = cv.KalmanFilter(2, 1)
lane_kalman.measurementMatrix = np.array([[1, 0]], np.float32)
lane_kalman.transitionMatrix = np.array([[1, 1], [0, 1]], np.float32)
lane_kalman.processNoiseCov = np.eye(2, dtype=np.float32) * 0.03
lane_kalman.measurementNoiseCov = np.array([[1]], np.float32) * 0.5

# === ì°¨ì„  ìƒ‰ìƒ í•„í„° ===
def color_space(img):
    img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)

    mask_yellow = cv.inRange(img_hsv, (15, 90, 140), (40, 255, 255))
    mask_white = cv.inRange(img_hsv, (0, 0, 210), (180, 40, 255))
    mask_red1 = cv.inRange(img_hsv, (0, 100, 100), (10, 255, 255))
    mask_red2 = cv.inRange(img_hsv, (170, 100, 100), (180, 255, 255))
    mask_red = cv.bitwise_or(mask_red1, mask_red2)

    mask = cv.bitwise_or(mask_white, mask_yellow)
    mask = cv.bitwise_or(mask, mask_red)

    result = cv.bitwise_and(img, img, mask=mask)
    return cv.cvtColor(result, cv.COLOR_BGR2GRAY)

# === ROI ì„¤ì • (í•˜ë‹¨ ì‚¬ê°í˜• ì˜ì—­) ===
def region_of_interest(img):
    height, width = img.shape
    polygon = np.array([[
        (int(0.2 * width), height),
        (int(0.8 * width), height),
        (int(0.6 * width), int(0.65 * height)),
        (int(0.4 * width), int(0.65 * height))
    ]], np.int32)
    mask = np.zeros_like(img)
    cv.fillPoly(mask, polygon, 255)
    return cv.bitwise_and(img, mask)

# === ì°¨ì„  ê²€ì¶œ ë° Kalman í•„í„° ì ìš© ===
def detect_lines(img, original_img):
    lines = cv.HoughLinesP(img, 1, np.pi / 180, threshold=100,
                           minLineLength=100, maxLineGap=20)
    line_img = np.zeros_like(original_img)
    lane_center_xs = []

    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            cx = int((x1 + x2) / 2)
            lane_center_xs.append(cx)
            cv.line(line_img, (x1, y1), (x2, y2), (0, 255, 0), 3)

    if lane_center_xs:
        avg_x = int(np.mean(lane_center_xs))
        measured = np.array([[np.float32(avg_x)]])
        lane_kalman.correct(measured)
        predicted = lane_kalman.predict()
        predicted_x = int(predicted[0])
        height = original_img.shape[0]
        cv.line(line_img, (predicted_x, height), (predicted_x, int(height * 0.6)), (255, 0, 0), 2)

    return cv.addWeighted(original_img, 0.8, line_img, 1, 1)

# === ë©”ì¸ ì‹¤í–‰ ===
def main():
    cap = cv.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
        return

    print("âœ… ì˜ìƒ ì—´ê¸° ì„±ê³µ. YOLO ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = YOLO(model_path)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("ğŸ”š ì˜ìƒ ì¢…ë£Œ")
            break

        masked = color_space(frame)
        edges = cv.Canny(masked, 80, 200)
        roi = region_of_interest(edges)
        lane_frame = detect_lines(roi, frame.copy())

        results = model.predict(frame, verbose=False)[0]
        yolo_frame = results.plot()

        combined = cv.addWeighted(lane_frame, 0.5, yolo_frame, 0.5, 0)

        # === í”„ë ˆì„ í¬ê¸° ì¶•ì†Œ í‘œì‹œ ===
        scale = 0.6
        resized = cv.resize(combined, None, fx=scale, fy=scale)
        cv.imshow("YOLO + Lane Detection with Kalman Filter", resized)

        if cv.waitKey(1) & 0xFF == 27:
            break

    cap.release()
    cv.destroyAllWindows()

if __name__ == "__main__":
    main()

